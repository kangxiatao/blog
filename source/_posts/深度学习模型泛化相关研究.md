---
title: 深度学习模型泛化相关研究
date: 2022-02-13 21:40:24
categories: 学习日志
tags:
  - 神经网络
  - 深度学习
  - 模型泛化
mathjax: true
toc: true
---

## 人工智能？道可道非恒道！

有点无趣，2022年了，人工智能还处于暴力学习的阶段。

去年我的大半时间花在神经网络的可解释性上，然后利用隐式损失和耦合梯度设计了在初始化前修剪模型的方法。
在应用层面似乎有些许价值，可是不论多大的稀疏率，大量的样本和模型暴力的求解方法总是显得深度学习有点蠢。
我对神经网络超长的训练时间愈发反感，虽然看过不少文献在模型优化方面的研究，但确实是不太看好目前模型的训练方式。

多模态和自学习等研究带来了一些曙光，但道可道非恒道。
我不知道当前在某个尺度空间下所谓人工智能的表现结果智能何在，且不说非一成不变的万物。
那么在对于人来说都是非恒道的世间，模型的泛化又能到何等地步？

书生意气，我不配在哲学层面讨论，毕竟目前的人工笨蛋也达不到。
虽然有一种基础科学被质子锁死的感觉，但路还是要一步步走的，在此记录一些深度学习模型泛化的相关研究。

怅寥廓，不知沉浮。

<!--more-->

## 损失函数

### Tilting the playingfield: Dynamical loss functions for machine learning

倾斜运动场：机器学习的动态损失函数

。。。

## #、---
