---
title: 神经网络剪枝综述
date: 2021-08-15 21:19:00
categories: 学习日志
tags:
  - 神经网络
  - 神经网络剪枝
toc: true
---

## 0，前言

在剪枝邻域还算是有些理解了，最近又在看些最新的文章，简单写点吧，也方便以后总结。

<!--more-->

## 1，剪枝需求

- 减少模型算力需求、存储大和延迟等问题
- 理论上通过剪枝能提高泛化能力
- 对模型的解释性和泛化能力相关的探索

## 2，神经网络剪枝的基本问题

- 怎么剪掉连通结构
  - 非结构化修剪
    - 不考虑参数之间的关系，性能优于结构化剪枝，但是过于稀疏，并不能达到硬件加速的需求。
  - 结构化修剪
    - 考虑模型的整体结构，移除部分连接在一起的权值，这样修剪很容易进行并行化处理。
  - 全局修剪
    - 将整个网络s%的权重移除
  - 局部修剪
    - 每一层修剪一定的比例
- 怎么选择重要的权重
  - 按权重大小修剪
    - 这种做法很实用，但是和L2正则化的思想有些矛盾。
  - 根据梯度变化来修剪
    - 或者更高阶的信息
  - 稀疏引导
    - 通过惩罚的方式来引导模型学习出一个稀疏的结构。
  - 根据先验知识选择
- 多久进行一次剪枝
  - 单次剪枝
    - 容易受到噪声影响
  - 迭代式剪枝
    - 更长的训练时间
- 何时执行剪枝步骤
  - 训练前
    - 等同于从头开始训练一个稀疏网络
  - 训练中
    - 每次都能对模型进行微调
  - 训练后
    - 训练收敛后修剪通常会降低泛化能力

## 3，最新研究进展

彩票假设表面了存在从头开始训练稀疏网络的可能，目前比较新的研究都是从这方面入手，相关论文写在阅读笔记中。

待补充。。。
