---
title: 图像处理之深度学习
date: 2021-09-10 21:28:03
categories: 学习日志
tags:
  - 图像处理
  - 机器视觉
  - 神经网络
  - Neural Network
toc: true
---

## 前言

图像方面的处理是人工智能发展的一个主要分支，同时具备极高的应用价值，在此总结一些工业上学术上使用较为广泛的模型，或是较为经典，或是个人熟悉。

<!--more-->

### 图像分类

- LeNet

    诞生于1994年，是最早的卷积神经网络之一，卷积网络架构的起点

- AlexNet

    2012年LSLVRC2012竞赛中的冠军网络，从这一年起，深度学习开始飞速发展

      - 首次利用GPU进行网络加速训练
      - 使用了ReLU激活函数
      - 使用了局部响应归一化LRN
      - 全连接层Dropout的使用

- VggNet

    诞生于2014年，作者尝试了很多结构，最大的亮点是采用3*3的小卷积核

- GoogLeNet

    Goog LeNet很明显是在向LeNet致敬，最早版本出自2014年

        - Inception 结构（不同特征尺度融合）
        - 1*1卷积核进行降维和映射处理
        - 辅助分类器帮助训练（防止梯度消失）
        - 丢弃全连接层（池化代替）

- ResNet

    2015年微软实验室提出，residual模块实现超深的网络结构（相当于短接），解决深层结构的梯度消失问题

    后续的ResNeXt修改了block，把过滤器拆开来计算（Group Convolution）

- DenseNet

    CVPR2017的oral，主要和ResNet及Inception网络做对比，简单讲，就是每一层的输入来自前面所有层的输出

- MobileNet

    Google2017年提出的轻量级网络，大幅度减少了参数与运算量

        - Depthwise separable convolution（深度可分离卷积）
        - 添加超参数控制模型规模

    v2主要是一个倒残差结构，然后修改了激活函数

    v3更新了Block（加入SE模块‘注意力机制’，添加通道权重），使用NAS搜索结构，并重新设计耗时层

- ShuffleNet

    旷视科技在2017年底提出的轻量级网络

        - channel shuffle（实现组之间的信息交流）
        - pointwise group convolutions（1*1卷积做group操作）

    v2提出FLOPs不能作为衡量模型的唯一标准，作者在其他反面优化了模型

- EfficientNet

    2019谷歌发表于ICML，作者同时探索输入分辨率、网络深度和宽度的影响

    v2发表在2021 CVPR，设计了更好的模型结构，在我看来最大的提升是渐进式学习策略，随着训练不同阶段选择不同的正则化强度（作者用了Dropout、RandAugment和Mixup这三种正则方法）

- Vision Transformer (ViT)

    2017年谷歌提出的Transformer已经在各种场景中被应用，终于在2020年谷歌在视觉领域采用Transformer取得了优异的性能

    核心思想就是把图片划分成区块序列传入ViT

        - 把图像分为几个区块 (patch)
        - 添加分类标志位
        - 线性变换转为 D 维特征向量
        - 加上位置编码向量
        - 通过Transformer Encoder层，对第一个类别输出设计分类器

- Swin Transformer
  
    2021年微软研究院发表，对ViT的一个改进

    ViT从头至尾都是对全局做self-attention，而swin-transformer是一个窗口在放大的过程，然后self-attention的计算是以窗口为单位去计算的

    这样相当于引入了局部聚合的信息，和CNN的卷积过程很相似

### 目标检测

- Faster-RCNN/FPN

    Faster R-CNN 是目标检测中的一个很经典的two stage算法，许多其他的目标检测算法都会运用到Faster R-CNN的部分结构或思想

    Faster R-CNN 由R-CNN，Fast R-NN改进演变而来

        - R-CNN是深度学习目标检测的开山之作（生成候选区域，分类，修正候选框）
        - Fast R-NN 先做卷积提取特征之后再提取对应的候选区
        - Faster R-CNN 等于 RPN + Fast R-NN，RPN选出区域，Fast R-NN检测
        - RPN 在每个位置上取三个不同面积的特征（经验所得）

    FPN 是2017年提出的一种网络，简单说就是把各层的特征图组合起来

- SSD/RetinaNet

    SSD 发表于ECCV 2016，模型是vgg改，得到6个特征图，设定不同的Prior Box

    RetinaNet 发表于CVPR 2017，SSD + FPN

- YOLO

    YOLO v1 2016 CVPR，网格化处理

    YOLO v2 2017 CVPR，添加BN层，更高分辨率，使用anchor，深浅特征图融合，动态图片大小

    YOLO v3 2018 CVPR，融合各种优势，残差结构，多特征图等

    YOLO v3spp，Mosaic图像增强（多个图片拼接），SPP模块（不同尺度特征融合），损失的修改（正负样本匹配）

### 图像分割

参考：[语义分割综述](https://blog.csdn.net/qq_41997920/article/details/96479243)

很酷，人工假智能，科技并带着趣味。

- FCN

    深度学习之语义分割开天辟地之作，于2014年提出，称为全卷积网络

      - 不含全连接层的全卷积网络，可适应任意尺寸输入
      - 反卷积层增大图像尺寸，输出精细结果
      - 结合不同深度层结果的跳级结构，确保鲁棒性和精确性

- UNet

    UNet是完全对称的，并有编码器解码器的概念

      - 切片的策略
      - 弹性变形数据增强
      - 使用加权loss

- SegNet

    轻量化上采用，记录池化位置索引，分割效果和速度双提升

- Multi-Scale

    提出和使用了空洞卷积

- Deeplab

    空洞卷积，图像金字塔，全连接条件随机场（结构化预测）

【后续版本pass】（图像领域太卷了，模型层出不穷，鼠鼠在此等一个革新）

云点分割（偷懒，也放在这里吧）

参考：[PointNet 家族简介](https://zhuanlan.zhihu.com/p/422962213)

- PointNet

    开山之祖

      - 排列不变性（maxpooling聚合信息）
      - 交互性（全局与局部特征concat）
      - 变换不变性（输入数据标准化）

- PointNet++

    点云版 UNet，分割区域，捕捉局部信息

      - set abstraction结构逐层提取特征（sampling:FPS最远距离采样，grouping:找领域点，PointNet提取特征）
      - 分类任务： PointNet（MLP）+max pooling + 2层full connection layers + softmax 提取全局特征
      - 分割任务：插值+concat+Pointnet来上采样点云数量并提取点云特征

- VoxelNet

    苹果公司在2016年提出，思路很直观，就是切成小块做处理。

      - 特征学习网络（Voxel划分，Grouping和Sampling，特征堆叠，4D Tensor稀疏表示）
      - 中间卷积层（用三维卷积聚合Voxel局部关系）
      - 区域提议网络（Region proposal network，3d目标检测）

- SECOND

    使用了稀疏 3D 卷积的优化VoxelNet（稀疏卷积实现将写在底层实现Blog中）

- PointPillars

    把垂直方向的点云压到网格上，使用 2D CNN 方法进行物体检测

- 中间省略一堆优异模型，下面概况最近研究的几个模型

- Point-Voxel

    NIPS19 spotlight，韩松实验室的工作，主要是两种方法的融合。

      - Point分支提取全局特征
      - Voxel分支提取局部特征

- [SPVNAS]([https://](https://arxiv.org/abs/2007.16100))

    ECCV2020，韩松实验室为了更高效的部署，提出了一种新的三维点云计算模块稀疏点云-栅格卷积 (SPVConv) 和3D神经网络结构自动搜索 (3D-NAS)

    主要在于稀疏的卷积实现和搜索，我打算利用剪枝的思路来尝试下稀疏搜索，不知是否有效。先仔细学习下代码，感觉写的还蛮好的，一些细节将记录在下面。

    呃，从底层到各种高级用法，看呆了，分割领域就到这里吧，之后的时间先务下正业。

To be continued ...
